nloop = 1000#
fv = read.csv("~/Google Drive/305-Fall2018/Exams_StudyGuides/Exam3/DataSets/FertileValley2.csv")#
y = fv$acrescorn#
x = fv$acrestot#
n = 20#
N = 95#
#
SRS = rep(NA, nloop)#
RE = rep(NA, nloop)#
R = rep(NA, nloop)#
#
for(i in 1:nloop){#
	s = sample(y, 20, replace = F)#
	sbar = mean(s)#
	SRS[i] = sbar#
}#
s_srs = sum( (s - sbar)^2)/n-1#
#
for(i in 1:nloop){#
	s1 = sample(y, 20, replace = F)#
	s2 = sample(x, 20, replace = F)#
	s1bar = mean(s1)#
	s2bar = mean(s2)#
	r = s1bar/s2bar#
	RE[i] = r#
}#
#
sr2 = sum( (s1 - r*s2)^2)/(n-1)#
DE_ratio = sr2/s_srs#
DE_ratio
ntry = 10000#
#
nloop = 1000#
fv = read.csv("~/Google Drive/305-Fall2018/Exams_StudyGuides/Exam3/DataSets/FertileValley2.csv")#
y = fv$acrescorn#
x = fv$acrestot#
n = 20#
N = 95#
#
possible = rep(NA, ntry)#
for(j in 1:ntry){#
SRS = rep(NA, nloop)#
RE = rep(NA, nloop)#
R = rep(NA, nloop)#
#
for(i in 1:nloop){#
	s = sample(y, 20, replace = F)#
	sbar = mean(s)#
	SRS[i] = sbar#
}#
s_srs = sum( (s - sbar)^2)/n-1#
#
for(i in 1:nloop){#
	s1 = sample(y, 20, replace = F)#
	s2 = sample(x, 20, replace = F)#
	s1bar = mean(s1)#
	s2bar = mean(s2)#
	r = s1bar/s2bar#
	RE[i] = r#
}#
#
sr2 = sum( (s1 - r*s2)^2)/(n-1)#
DE_ratio = sr2/s_srs#
DE_ratio#
#
possible[i] = DE_ratio#
}
ntry = 1000#
#
nloop = 1000#
fv = read.csv("~/Google Drive/305-Fall2018/Exams_StudyGuides/Exam3/DataSets/FertileValley2.csv")#
y = fv$acrescorn#
x = fv$acrestot#
n = 20#
N = 95#
#
possible = rep(NA, ntry)#
for(j in 1:ntry){#
SRS = rep(NA, nloop)#
RE = rep(NA, nloop)#
R = rep(NA, nloop)#
#
for(i in 1:nloop){#
	s = sample(y, 20, replace = F)#
	sbar = mean(s)#
	SRS[i] = sbar#
}#
s_srs = sum( (s - sbar)^2)/n-1#
#
for(i in 1:nloop){#
	s1 = sample(y, 20, replace = F)#
	s2 = sample(x, 20, replace = F)#
	s1bar = mean(s1)#
	s2bar = mean(s2)#
	r = s1bar/s2bar#
	RE[i] = r#
}#
#
sr2 = sum( (s1 - r*s2)^2)/(n-1)#
DE_ratio = sr2/s_srs#
DE_ratio#
possible[j] = DE_ratio#
}
min(possible)
summary(possible)
SRS = rep(NA, nloop)#
RE = rep(NA, nloop)#
R = rep(NA, nloop)#
#
for(i in 1:nloop){#
	s = sample(y, 20, replace = F)#
	sbar = mean(s)#
	SRS[i] = sbar#
}#
s_srs = sum( (s - sbar)^2)/n-1#
#
for(i in 1:nloop){#
	s1 = sample(y, 20, replace = F)#
	s2 = sample(x, 20, replace = F)#
	s1bar = mean(s1)#
	s2bar = mean(s2)#
	r = s1bar/s2bar#
	RE[i] = r#
}#
#
sr2 = sum( (s1 - r*s2)^2)/(n-1)#
DE_ratio = sr2/s_srs#
DE_ratio
library(dplyr)
subset()
Str1 = subset(fv, acrestot < 300, select = acrescorn)
Str1
Str1 = subset(fv, acrestot < 300, select = acrescorn)#
Str2 = subset(fv, acrestot >= 300 & acrestot < 600, select = acrescorn)#
Str3 = subset(fv, acrestot >= 601 & acrestot < 900, select = acrescorn)#
Str4 = subset(fv, acrestot >= 900, select = acrescorn)
N = length(fv$acrestot)
N
Ni= c(length(Str1$acrescorn),length(Str2$acrescorn),length(Str3$acrescorn),length(Str4$acrescorn) )
Ni
sum(Ni)
fv = read.csv("~/Google Drive/305-Fall2018/Exams_StudyGuides/Exam3/DataSets/FertileValley2.csv")#
#
Str1 = subset(fv, acrestot < 300, select = acrescorn)#
Str2 = subset(fv, acrestot >= 300 & acrestot < 600, select = acrescorn)#
Str3 = subset(fv, acrestot >= 601 & acrestot < 900, select = acrescorn)#
Str4 = subset(fv, acrestot >= 900, select = acrescorn)#
N = length(fv$acrestot)#
N#
strVecs = rep(NA, reps)#
SRSVecs = rep(NA, reps)#
#
n = rep(5, 4)#
n#
Ni= c(length(Str1$acrescorn),length(Str2$acrescorn),length(Str3$acrescorn),length(Str4$acrescorn) )#
sum(Ni)#
for(i in 1:reps){#
	samp1 = sample(Str1$acrescorn, 5, replace = F)#
	samp2 = sample(Str2$acrescorn, 5, replace = F)#
	samp3 = sample(Str3$acrescorn, 5, replace = F)#
	samp4 = sample(Str4$acrescorn, 5, replace = F)#
	svar = c(var(samp1), var(samp2), var(samp3), var(samp4))#
	Vhat = 1/95^2 * sum(Ni^2 * (1 - n/Ni) * svar/n)#
	strVecs[i] = Vhat#
	s = c(samp1, samp2, samp3, samp4)#
	vhatSRS2 = (1 - 20/N) * var(s)/20#
	SRSVecs[i] = vhatSRS2#
}#
#
mean(strVecs)/mean(SRSVecs)
library(rstanarm)
library(foreign)#
library(ggplot2)#
library(MASS)#
library(Hmisc)#
library(reshap2)#
library(rstanarm)#
#
dat = read.dta("https://stats.idre.ucla.edu/stat/data/ologit.dta")#
head(dat)#
#
print(polr(apply ~ public + gpa, data = dat))#
#
post0 <- stan_polr(apply ~ public + gpa, data = dat, prior = R2(0.25), prior_counts = dirichlet(1), seed = 2020)
post0 <- stan_polr(apply ~ public + pared + gpa, data = dat, prior = R2(0.25), prior_counts = dirichlet(1), seed = 2020)
print(polr(apply ~ public + pared + gpa, data = dat))
out <- polr(apply ~ public + pared + gpa, data = dat)
confint(out)
head(post0)
names(post0)
post0$family
post0$stanfit
pi = predictive_interval(post0)
bayes_R2(post0)
post1 <- stan_polr(apply ~ public + gpa, data = dat, prior = R2(0.25), prior_counts = dirichlet(1), seed = 2020)
post1 <- stan_polr(apply ~ public + gpa, data = dat, prior = R2("median" = 0.25), prior_counts = dirichlet(1), seed = 2020)
post1 <- stan_polr(apply ~ public + gpa, data = dat, prior = R2(median = 0.25), prior_counts = dirichlet(1), seed = 2020)
post1 <- stan_polr(apply ~ public + gpa, data = dat, prior = R2(what = c("median" = 0.25)), prior_counts = dirichlet(1), seed = 2020)
post1 <- stan_polr(apply ~ public + gpa, data = dat, prior = R2(location = NULL, what = c("median" = 0.25)), prior_counts = dirichlet(1), seed = 2020)
post1 <- stan_polr(apply ~ public + gpa, data = dat, prior = R2(location = NULL, what = c('median' = 0.25)), prior_counts = dirichlet(1), seed = 2020)
help(R2)
post1 <- stan_polr(apply ~ public + gpa, data = dat, prior = R2(0.25, what = c('median')), prior_counts = dirichlet(1), seed = 2020)
post0 <- stan_polr(apply ~ public + pared + gpa, data = dat, prior = R2(0.25, what = c('median')), prior_counts = dirichlet(1), seed = 2020)
loo(post0)
loo(post0, post1)
library(loo)
linpred <- posterio_linpred(post0)
linpred <- posterior_linpred(post0, transform = T)
linpred
head(linpred)
preds <- posterior_linpred(post0, transform = T)#
pred <- colMeans(preds)
head(preds)
pred_cat <- rep(1, length(pred))
pred_cat <- rep(2, length(pred))
pred_cat <- rep(2, length(pred))#
pred_cat[which(pred > post0$zeta[3])] <- 3#
pred_cat[which(pred <= post0$zeta[1])] <- 1
table(pred_cat, dat$apply)
pred_cat <- rep(1, length(pred))#
pred_cat[which(pred > post0$zeta[1])] <- 2#
pred_cat[which(pred <= post0$zeta[2])] <- 3#
table(pred_cat, dat$apply)
pred_cat <- rep(2, length(pred))#
pred_cat[which(pred > post0$zeta[2])] <- 3#
pred_cat[which(pred <= post0$zeta[1])] <- 1#
table(pred_cat, dat$apply)
plot(loo(post0))
post0$zeta
summary(post0)
summary(out)
summary(pred)
check_all_diagnostics()
calibration()
table(preds)
ordered_logistic_rng()
preds <- posterior_linpred(post0, transform = T)
preds <- posterior_linpred(post0, transform = F)
pred <- colMeans(preds)
hist(pred)
print(post0, digits = 2)
out = pp_check(post0)
dim(out)
head(out)
nreps <- max(post_preds$rep_id)
nreps
post_preds$rep_id
tail(post_preds)
names(post_preds_out)
table(post_preds$y_id)
table(post_preds$rep_id)
tmp <- post_preds[which(post_preds$y_id == 1), ]
tmp
dat[1,]
tmp <- post_preds[which(post_preds$y_id == 2), ]
table(tmp$value)
dat[2,]
library(foreign)#
library(ggplot2)#
library(MASS)#
library(Hmisc)#
library(reshap2)#
library(rstanarm)#
library(loo)
dat <-  read.dta("https://stats.idre.ucla.edu/stat/data/ologit.dta")#
head(dat)#
out <- polr(apply ~ public + pared + gpa, data = dat)#
summary(out)#
confint(out)#
post0 <- stan_polr(apply ~ public + pared + gpa, data = dat, prior = R2(0.25, what = c('median')), prior_counts = dirichlet(1), seed = 2020)#
#
post0$zeta#
print(post0, digits = 2)#
#
table(dat$apply)/dim(dat)[1]#
post_pred_out = pp_check(post0)
library(bayesplot)
ppc_bars(pp_check(post0))
head(post_preds)
ppc_bars((post0))
pp_check(post0)
post_pred_out$value
yrep_matrix <- matrix(post_pred_out$value, byrow = T)
post_preds <- post_pred_out$data
yrep_matrix <- matrix(post_preds$value, byrow = T)
dim(post_preds)
post_pred_out = pp_check(post0)
names(post_pred_out)
names(post_preds)
nobs <- length(dat$apply)
yrep_matrix <- matrix(post_preds$value, byrow = T, nrow = nobs)
ppc_bars(dat$apply, yrep_matrix)
yrep_matrix <- matrix(post_preds$value, byrow = F, ncol = nobs)
yrep_matrix <- matrix(post_preds$value, byrow = T ncol = nobs)
yrep_matrix <- matrix(post_preds$value, byrow = T, ncol = nobs)
ppc_bars(as.numeric(dat$apply), yrep_matrix, freq = F)
table(dat$apply)/dim(dat)[1]
table(predict(out))
nobs <- dim(dat)[1]
table(predict(out))/nobs
predict(out)
table(predict(out, type = "response"))/nobs
table(predict(out, type = "probs"))/nobs
table(predict(out, type = "class"))/nobs
table(predict(out, type = "p"))
table(predict(out, type = "p"))[1,]
table(predict(out, type = "p"))[1]
table(predict(out, type = "p"))[2]
table(predict(out, type = "p"))[500]
predict(out, type = "p"))
predict(out, type = "p")
head( predict(out, type = "p") )
head( predict(out, type = "c") )
table(predict(out, type = "c"), dat$apply)
post0 <- stan_polr(apply ~ public + pared + gpa, data = dat, prior = R2(0.25, what = c('median')), prior_counts = dirichlet(1), seed = 2020)#
#
post0$zeta#
print(post0, digits = 2)
post_pred_out = pp_check(post0)#
names(post_pred_out)#
post_preds <- post_pred_out$data#
names(post_preds)#
dim(post_preds)#
nobs <- length(dat$apply)#
yrep_matrix <- matrix(post_preds$value, byrow = T, ncol = nobs)#
#
ppc_bars(as.numeric(dat$apply), yrep_matrix, freq = F)
post0$zeta#
print(post0, digits = 2)#
pp_check(post0)#
post_pred_out = pp_check(post0)#
names(post_pred_out)#
post_preds <- post_pred_out$data#
names(post_preds)#
dim(post_preds)
nobs <- length(dat$apply)#
yrep_matrix <- matrix(post_preds$value, byrow = T, ncol = nobs)#
ppc_bars(as.numeric(dat$apply), yrep_matrix, freq = F)
as.numeric(dat$apply)
yrep_matrix
ppc_bars(as.numeric(dat$apply), yrep_matrix)
post1 <- stan_polr(apply ~ public + gpa, data = dat, prior = R2(0.25, what = c('median')), prior_counts = dirichlet(1), seed = 2020)#
#
loo_compare(post0, post1)
loo_compare(post0, post1)
help(loo_compare)
loo_compare(loo(post0), loo(post1) )
waic(post0)
waic(post1)
loo_compare(waic(post0), waic(post1))
help(pp_check)
table(dat$apply)/nobs
table(predict(out, type = "c"))/nobs
x = seq(30, 70, by = 1)#
#
mean = -0.95*x^2 +95*x - 2200#
plot(x, mean)#
y = rnorm
mean = -0.95*x^2 +75*x - 2200#
plot(x, mean)
mean = -0.95*x^2 +107*x - 2200#
plot(x, mean)
mean = (-0.95*x^2 +107*x - 2200)/100#
plot(x, mean)
mean = (-0.95*x^2 +107*x - 2200)/10#
plot(x, mean)
m1 = (-0.95*x^2 +107*x - 2100)/10
lines(x, m1)
location = rep(1:4, each = 10)#
field = rep(1:10, 4)
location
field
set.seed(20)#
x1 = runif(10, 30, 70)#
x2 = runif(10, 30, 70)#
x3 = runif(10, 30, 70)#
x4 = runif(10, 30, 70)#
#
m1 = (-0.95*x1^2 +107*x1 - 2100)/10#
m2 = (-0.95*x2^2 +107*x2 - 2300)/10#
m3 = (-0.95*x3^2 +107*x3 - 2100)/10#
m4 = (-0.95*x4^2 +107*x4 - 2100)/10#
#
location = rep(1:4, each = 10)#
field = rep(1:10, 4)#
means = c(m1, m2, m3, m4)#
y = rnorm(40, mean = means, sd = 5)
x = c(x1, x2, x3, x4)#
plot(x, y)
location = rep(a:d, each = 10)
set.seed(20)#
x1 = runif(10, 30, 70)#
x2 = runif(10, 30, 70)#
x3 = runif(10, 30, 70)#
x4 = runif(10, 30, 70)#
#
m1 = (-0.95*x1^2 +107*x1 - 2100)/10#
m2 = (-0.95*x2^2 +107*x2 - 2300)/10#
m3 = (-0.95*x3^2 +107*x3 - 2100)/10#
m4 = (-0.95*x4^2 +107*x4 - 2100)/10#
#
location = rep(c("a", "b", "c", "d"), each = 10)#
field = rep(1:10, 4)#
means = c(m1, m2, m3, m4)#
y = rnorm(40, mean = means, sd = 5)#
#
x = c(x1, x2, x3, x4)#
plot(x, y)
mydata = data.frame(location, field, "fertilizer" = x, "yield" = y)
getwd()
write.csv(mydata, "SimulatedYieldData.csv", row.names = F)
library(ggplot2)
library(readxl)
yield_data = read_csv("/Users/zacharyweller/Desktop/SimulatedYieldData.csv")
library(readr)#
library(ggplot2)#
yield_data = read_csv("/Users/zacharyweller/Desktop/SimulatedYieldData.csv")
yieldplot <- ggplot(yield_data) + geom_point(x = fertilizer, y = yield, col = location)
names(yield_data)
yieldplot <- ggplot(yield_data) + geom_point(x = fertilizer, y = yield, col = location, data = yield_data)
yieldplot <- ggplot(x = fertilizer, y = yield, data = yield_data) + geom_point(x = fertilizer, y = yield, col = location, data = yield_data)
yieldplot <- ggplot(x = fertilizer, y = yield, data = yield_data)
yieldplot <- ggplot(x = fertilizer, y = yield, data = yield_data) + geom_point(aes(x = fertilizer, y = yield, col = location), data = yield_data)#
yieldplot
lmOut <- lm(yield ~ fertilizer + I(fertilizer^2), data = yield_data)
yield_plot2 <- yield_plot + geom_smooth( method = "lm", formula = yield ~ fertilizer + I(fertilizer^2) )
yield_plot2 <- yieldplot + geom_smooth( method = "lm", formula = yield ~ fertilizer + I(fertilizer^2) )
yield_plot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = yield ~ fertilizer + I(fertilizer^2) )
yield_plot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = yield ~ fertilizer + I(fertilizer^2), data = yield_data )#
#
yield_plot2
yield_plot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = y~ x+ x^2, data = yield_data )
yield_plot2
yield_plot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = y ~ x+ I(x)^2, data = yield_data )#
#
yield_plot2
names(yield_data)#
yieldplot <- ggplot(x = fertilizer, y = yield, data = yield_data) + geom_point(aes(x = fertilizer, y = yield, col = location), data = yield_data)#
yieldplot
yieldplot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = y ~ x+ I(x)^2, data = yield_data )#
#
yieldplot2
yieldplot2 <- yieldplot + geom_smooth(method = "lm", formula = y ~ x+ I(x)^2)#
#
yieldplot2
yieldplot <- ggplot(x = fertilizer, y = yield, data = yield_data) + geom_point(aes(x = fertilizer, y = yield, col = location))#
yieldplot
lmOut <- lm(yield ~ fertilizer + I(fertilizer^2), data = yield_data)#
summary(lmOut)#
#
yieldplot2 <- yieldplot + geom_smooth(method = "lm", formula = y ~ x+ I(x)^2)#
#
yieldplot2
yieldplot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = y ~ x+ I(x)^2)#
#
yieldplot2
yieldplot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = y ~ x + I(x)^2)#
#
yieldplot2
yieldplot <- ggplot(x = fertilizer, y = yield, data = yield_data) + geom_point(aes(x = fertilizer, y = yield)#
yieldplot#
lmOut <- lm(yield ~ fertilizer + I(fertilizer^2), data = yield_data)#
summary(lmOut)#
#
yieldplot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = y ~ x + I(x)^2)#
#
yieldplot2
yieldplot <- ggplot(x = fertilizer, y = yield, data = yield_data) + geom_point(aes(x = fertilizer, y = yield, col = location))#
yieldplot#
lmOut <- lm(yield ~ fertilizer + I(fertilizer^2), data = yield_data)#
summary(lmOut)#
#
yieldplot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = y ~ x+ I(x^2) )#
#
yieldplot2
lmOut <- lm(yield ~ location + fertilizer + I(fertilizer^2), data = yield_data)#
summary(lmOut)
install.packages("ggiraphExtra")
library(ggiraphExtra)
ggPredict(lmOut)
summary(lmOut)
yieldplot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield, group = location), method = "lm", formula = y ~ x+ I(x^2) )#
yieldplot2
yieldplot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield, group = location, col = location), method = "lm", formula = y ~ x+ I(x^2) )#
yieldplot2
lmOut <- lm(yield ~ fertilizer + I(fertilizer^2), data = yield_data)#
summary(lmOut)#
#
yieldplot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield), method = "lm", formula = y ~ x+ I(x^2) )#
yieldplot2#
lmOut2 <- lm(yield ~ location + fertilizer + I(fertilizer^2), data = yield_data)#
summary(lmOut2)#
#
yieldplot2 <- yieldplot + geom_smooth(aes(x = fertilizer, y = yield, group = location, col = location), method = "lm", formula = y ~ x+ I(x^2) )#
yieldplot2#
anova(lmOut, lmOut2)
library(lme4)
lmOut_re <- lmer(yield ~ (1|location) + fertilizer + I(fertilizer^2), data = yield_data)
summary(lmOut_re)
y = c(18, 22, 140)#
py = c(0.75, 0.24, 0.01)#
mu = sum(y*py)#
mu#
v = sum( (y - mu)^2 * py)#
sqrt(v)#
pop = sample(y, size = 25000, prob = py, replace = T)#
hist(pop)#
mean(pop)#
sd(pop)
nloop = 5000#
ybar_vec = rep(NA, nloop)#
for(i in 1:nloop){#
	samp = sample(pop, size = 16, replace = F)#
	ybar_vec[i] = mean(samp)#
}#
#
mean(ybar_vec)#
sd(ybar_vec)#
hist(ybar_vec, breaks = 50)
x = 1:5#
y = c(0.5, 0.6, 0.7, 0.75, 0.76)#
z = y - 0.3#
lower_y = c(0.4, 0.51, 0.64, 0.71, 0.75)#
upper_y = y + (y - lower)#
plot(x, y, type = "b", pch = 16, ylim = c(0, 1), xlab = "Drives", ylab = "Proportion 'Captured'")#
#
polygon( c(x, rev(x) ), c(lower_y, rev(upper_y) ), border = NA, col = rgb(0, 0, 0, alph = 0.2))#
lines(x, z, col = "red", type = "b", pch = 16)#
lower_z = lower_y - 0.3#
upper_z = upper_y - 0.3#
polygon( c(x, rev(x) ), c(lower_z, rev(upper_z) ), border = NA, col = rgb(1, 0, 0, alph = 0.2))#
legend("bottomright", legend = c("Proporiton of Leaks", "Proportion of Emissions"), col = c("black", "red"), lty = 1, lwd = 2)
x = 1:5#
y = c(0.5, 0.6, 0.7, 0.75, 0.76)#
z = y - 0.3#
lower_y = c(0.4, 0.51, 0.64, 0.71, 0.75)#
upper_y = y + (y - lower_y)#
plot(x, y, type = "b", pch = 16, ylim = c(0, 1), xlab = "Drives", ylab = "Proportion 'Captured'")#
#
polygon( c(x, rev(x) ), c(lower_y, rev(upper_y) ), border = NA, col = rgb(0, 0, 0, alph = 0.2))#
lines(x, z, col = "red", type = "b", pch = 16)#
lower_z = lower_y - 0.3#
upper_z = upper_y - 0.3#
polygon( c(x, rev(x) ), c(lower_z, rev(upper_z) ), border = NA, col = rgb(1, 0, 0, alph = 0.2))#
legend("bottomright", legend = c("Proporiton of Leaks", "Proportion of Emissions"), col = c("black", "red"), lty = 1, lwd = 2)
library(geoR)#
library(fields)#
library(mvtnorm)
install.packages("geoR")
library(geoR)#
library(fields)#
library(mvtnorm)#
#
setwd("~/Dropbox/GradShow/Ranalysis")#
#
x = seq(0, 12, by = 0.25)#
y = seq(0, 12, by = 0.25)#
#
coords = expand.grid(x,y)#
n = dim(coords)[1]#
#
sigma.sq <- 2#
tau.sq <- 0.5#
phi <- 1/6#
h = seq(0, 100, by = 0.5)#
ch = sigma.sq*exp(-phi*h)#
cor = ch/(sigma.sq + tau.sq)
h = seq(0, 100, by = 0.5)#
ch = sigma.sq*exp(-phi*h)#
cor = ch/(sigma.sq + tau.sq)#
svar = (sigma.sq + tau.sq) - sigma.sq*exp(-phi*h)#
par(mfrow = c(2,2))#
plot(h, svar, type = "l", ylim = c(0, 3), main = "semivariance")#
plot(h, ch, type = "l", main = "covariance")#
plot(h, cor, type = "l", ylim = c(0,1), main = "correlation")
sigma.sq <- 2#
#
tau.sq <- 0.5#
#
phi <- 1/6#
h = seq(0, 100, by = 0.5)#
ch = sigma.sq*exp(-phi*h)#
cor = ch/(sigma.sq + tau.sq)#
svar = (sigma.sq + tau.sq) - sigma.sq*exp(-phi*h)#
par(mfrow = c(2,2))#
plot(h, svar, type = "l", ylim = c(0, 3), main = "semivariance")#
plot(h, ch, type = "l", main = "covariance")#
plot(h, cor, type = "l", ylim = c(0,1), main = "correlation")
D <- as.matrix(dist(coords))#
#
R <- sigma.sq * exp(-phi*D)#
R <- R + diag(tau.sq, nrow = n, ncol = n)#
set.seed(201)#
#
z <- rmvnorm(1,rep(0,n), R, method = c("chol"))#
z <- z - mean(z)#
zmat = matrix(z, nrow = length(y), ncol = length(x), byrow = T)#
image.plot(x, y, zmat)
x.shift = -102#
y.shift = 37#
image.plot(x+x.shift, y+y.shift, zmat,#
ylab = "lat", xlab = "long",#
cex.main = 1.80, pty = "s", legend.cex = 0)#
map("state", add = T, lwd = 2)#
mtext("Isotropic Spatial Process", side = 3, line = 0.5, cex = 1.2, font = 2)
zmat.iso <- zmat#
#
pdf(file = "isotropic.pdf")#
image.plot(x+x.shift, y+y.shift, zmat,#
ylab = "lat", xlab = "long", main = "Stationary & Isotropic Spatial Process",#
cex.main = 1.80, pty = "s")#
map("state", add = T, lwd = 2)#
dev.off()
aniso.angle <- pi/4#
#
aniso.ratio <- 2.5#
#
coordsA <-  coords.aniso(coords, c(aniso.angle, aniso.ratio))#
#
Da <- as.matrix(dist(coordsA))#
#
R <- sigma.sq * exp(-phi*Da)#
R <- R + diag(tau.sq, nrow = n, ncol = n)#
set.seed(236)#
z <- rmvnorm(1,rep(0,n), R, method = c("chol"))#
z <- z - mean(z)#
zmat = matrix(z, nrow = length(y), ncol = length(x), byrow = T)#
image.plot(x, y, zmat)#
#
zmat.anis <- zmat#
#
x.shift = -102#
y.shift = 37#
image.plot(x+x.shift, y+y.shift, zmat,#
xlab = "long", ylab = "lat", main = "Stationary & Anisotropic Spatial Process",#
cex.main = 1.80, pty = "s")#
map("state", add = T, lwd = 2)
set.seed(110)#
x = runif(200,0,15)#
y = runif(200,0,15)#
#
coords = cbind(x,y)#
n = dim(coords)[1]#
#
sigma.sq <- 2#
tau.sq <- 0.5#
phi <- 1/3#
h = seq(0, 22, by = 0.5)#
ch = sigma.sq*exp(-phi*h)#
cor = ch/(sigma.sq + tau.sq)#
svar = (sigma.sq + tau.sq) - sigma.sq*exp(-phi*h)#
par(mfrow = c(2,2))#
plot(h, svar, type = "l", ylim = c(0, 3), main = "semivariance")#
plot(h, ch, type = "l", main = "covariance")#
plot(h, cor, type = "l", ylim = c(0,1), main = "correlation")#
D <- as.matrix(dist(coords))#
R <- sigma.sq * exp(-phi*D)#
R <- R + diag(tau.sq, nrow = n, ncol = n)#
set.seed(201)#
z <- rmvnorm(1,rep(0,n), R, method = c("chol"))#
z <- z - mean(z)#
zmat = matrix(z, nrow = length(y), ncol = length(x), byrow = T)#
image.plot(x, y, zmat)#
#
spdata = cbind(coords, t(z))#
#
spgeo = as.geodata(spdata, coords.col = 1:2, data.col = 3)#
plot(spgeo)#
summary(spgeo)#
#
sample.var = variog(spgeo)#
plot(h, svar, ylim  = c(0, 4), type = "l", lwd = 2)#
lines(sample.var)
library(dslabs)
library(dslabs)#
mnist <- read_mnist()
mnist <- read_mnist()
library(readmnist)
setwd("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata")
out = Read.mnist("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/train-images-idx3-ubyte.gz")
fname <- file("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/train-images-idx3-ubyte", "rb")
readBin(fname, integer(), n = 1, endian="big")
m = (matrix(readBin(f,integer(), size=1, n=28*28, endian="big"),28,28))
m = (matrix(readBin(fname,integer(), size=1, n=28*28, endian="big"),28,28))
m
dim(m)
library(readr)library(dplyr)mnist_raw <- read_csv("https://pjreddie.com/media/files/mnist_train.csv", col_names = FALSE)
library(readr)#
library(dplyr)#
mnist_raw <- read_csv("https://pjreddie.com/media/files/mnist_train.csv", col_names = FALSE)
library(tidyr)pixels_gathered <- mnist_raw %>%  head(10000) %>%  rename(label = X1) %>%  mutate(instance = row_number()) %>%  gather(pixel, value, -label, -instance) %>%  tidyr::extract(pixel, "pixel", "(\\d+)", convert = TRUE) %>%  mutate(pixel = pixel - 2,         x = pixel %% 28,         y = 28 - pixel %/% 28)pixels_gathered
tidyr::extract(pixel, "pixel", "(\\d+)", convert = TRUE) %>%  mutate(pixel = pixel - 2,         x = pixel %% 28,         y = 28 - pixel %/% 28)#
pixels_gathered
load_image_file <- function(filename) {#
   ret = list()#
    f = file(filename,'rb')#
    readBin(f,'integer',n=1,size=4,endian='big')#
    ret$n = readBin(f,'integer',n=1,size=4,endian='big')#
    nrow = readBin(f,'integer',n=1,size=4,endian='big')#
    ncol = readBin(f,'integer',n=1,size=4,endian='big')#
    x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)#
    ret$x = matrix(x, ncol=nrow*ncol, byrow=T)#
    close(f)#
    ret#
}#
#
load_label_file <- function(filename) {#
    f = file(filename,'rb')#
    readBin(f,'integer',n=1,size=4,endian='big')#
    n = readBin(f,'integer',n=1,size=4,endian='big')#
    y = readBin(f,'integer',n=n,size=1,signed=F)#
    close(f)#
    y#
}
train <- load_image_file("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/train-images-idx3-ubyte")
head(train)
names(train)
dim(train$x)
test <- load_image_file("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/t10k-images-idx3-ubyte")
dim(test)
class(test)
dim(test$x)
train$y <- load_label_file("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/train-labels-idx1-ubyte")
train <- load_image_file("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/train-images-idx3-ubyte")#
test <- load_image_file("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/t10k-images-idx3-ubyte")#
#
train$y <- load_label_file("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/train-labels-idx1-ubyte")#
test$y <- load_label_file("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/t10k-labels-idx1-ubyte.gz")
test$y <- load_label_file("/Users/zacharyweller/Google Drive/Teaching-CourseDocuments/MNISTdata/t10k-labels-idx1-ubyte")
hist(test$y)
